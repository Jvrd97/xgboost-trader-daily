import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import mean_absolute_error, root_mean_squared_error, r2_score, mean_squared_error
from sklearn.model_selection import TimeSeriesSplit, GridSearchCV
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import StandardScaler
from sklearn.base import clone
from datetime import datetime
import os
import json
import glob
import json


class MLHelper:
    def __init__(self, y_true, y_pred):
        # —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–æ–ª—å–∫–æ Series –æ–¥–Ω–æ–π –¥–ª–∏–Ω—ã
        self.y_true = pd.Series(y_true).reset_index(drop=True)
        self.y_pred = pd.Series(y_pred).reset_index(drop=True)

    # --------- –ú–µ—Ç—Ä–∏–∫–∏ ---------
    def rmse(self):
        return root_mean_squared_error(self.y_true, self.y_pred)

    def mae(self):
        return mean_absolute_error(self.y_true, self.y_pred)

    def mape(self):
        y_true = np.array(self.y_true)
        y_pred = np.array(self.y_pred)

        mask = y_true != 0
        if mask.sum() == 0:
            return np.nan

        return np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100

    def metrics(self):
        return {
            "RMSE": self.rmse(),
            "MAE": self.mae(),
            "MAPE (%)": self.mape()
        }

    # --------- –ì—Ä–∞—Ñ–∏–∫ ---------
    def plot(self, title="Model Evaluation"):
        plt.figure(figsize=(25, 5))
        plt.plot(self.y_true, label="True", linewidth=2)
        plt.plot(self.y_pred, label="Predicted", linewidth=2)
        plt.title(title)
        plt.xlabel("Index")
        plt.ylabel("Value")
        plt.legend()
        plt.grid()
        plt.show()

    # --------- –í—Å—ë –≤–º–µ—Å—Ç–µ ---------
    def evaluate(self, title="Model Evaluation"):
        self.plot(title)
        return self.metrics()
    
    @staticmethod
    def simple_forecast_metrics(y_true, y_pred):
        
        mae = mean_absolute_error(y_true, y_pred)
        rmse = np.sqrt(mean_squared_error(y_true, y_pred))
        r2 = r2_score(y_true, y_pred)
        
        print(f"MAE: {mae}")
        print(f"R2: {r2}")
        print(f"RMSE: {rmse}")
        
        # 2. FIX THE PLOTTING INDEX
        # Check if y_true is a Pandas Object to get the correct dates/index
        if hasattr(y_true, 'index'):
            plot_index = y_true.index
            y_true_values = y_true.values
        else:
            plot_index = range(len(y_true))
            y_true_values = y_true

        plt.figure(figsize=(25, 5))
        
        # Pass 'plot_index' as the X-axis for BOTH lines
        plt.plot(plot_index, y_true_values, label="True", linewidth=2)
        plt.plot(plot_index, y_pred, label="Predicted", linewidth=2, linestyle='--')
        
        plt.title("Model Evaluation")
        plt.xlabel("Index / Date")
        plt.ylabel("Value")
        plt.legend()
        plt.grid(True)
        plt.show()
        
        

        # MAPE (Mean Absolute Percentage Error) - —Å—Ä–µ–¥–Ω—è—è –∞–±—Å–æ–ª—é—Ç–Ω–∞—è –ø—Ä–æ—Ü–µ–Ω—Ç–Ω–∞—è –æ—à–∏–±–∫–∞
        # –û—Å—Ç–æ—Ä–æ–∂–Ω–æ: –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç –∫–æ–≥–¥–∞ y_true –±–ª–∏–∑–∫–æ –∫ 0
        
    # evaluate model
    @staticmethod
    def evaluate_forecast_full(predictions, y_true, df_real_future, forecaster, features, target,  to_json=True):
    
            # === 1. –ò–ó–í–õ–ï–ß–ï–ù–ò–ï –î–ê–ù–ù–´–• ===
        # Convert predictions to list/array
        if isinstance(predictions, dict):
            predictions = list(predictions.values())
        elif isinstance(predictions, (pd.Series, pd.DataFrame)):
            predictions = predictions.values
        else:
            predictions = np.array(predictions)
        
        # Convert y_true to array
        if isinstance(y_true, pd.Series):
            y_true = y_true.values
        elif isinstance(y_true, pd.DataFrame):
            y_true = y_true.values
        elif isinstance(y_true, list):
            y_true = np.array(y_true)  # ‚úÖ FIX: lists to numpy array
        else:
            y_true = np.array(y_true)
        
        # ‚úÖ CRITICAL: Ensure df_real_future has same length as predictions
        if len(df_real_future) != len(predictions):
            print(f"‚ö†Ô∏è  WARNING: df_real_future has {len(df_real_future)} rows, "
                f"but predictions has {len(predictions)} values.")
            print(f"   Using only first {len(predictions)} rows of df_real_future")
            df_real_future = df_real_future.iloc[:len(predictions)]

        # === 2. –†–ê–°–ß–Å–¢ –ú–ï–¢–†–ò–ö –û–®–ò–ë–û–ö ===

        # MAE (Mean Absolute Error) - —Å—Ä–µ–¥–Ω—è—è –∞–±—Å–æ–ª—é—Ç–Ω–∞—è –æ—à–∏–±–∫–∞
        mae = mean_absolute_error(y_true, predictions)

        # RMSE (Root Mean Squared Error) - –∫–æ—Ä–µ–Ω—å –∏–∑ —Å—Ä–µ–¥–Ω–µ–π –∫–≤–∞–¥—Ä–∞—Ç–∏—á–Ω–æ–π –æ—à–∏–±–∫–∏
        rmse = np.sqrt(mean_squared_error(y_true, predictions))
            
        r2 = r2_score(y_true, predictions)

        # MAPE (Mean Absolute Percentage Error) - —Å—Ä–µ–¥–Ω—è—è –∞–±—Å–æ–ª—é—Ç–Ω–∞—è –ø—Ä–æ—Ü–µ–Ω—Ç–Ω–∞—è –æ—à–∏–±–∫–∞
        # –û—Å—Ç–æ—Ä–æ–∂–Ω–æ: –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç –∫–æ–≥–¥–∞ y_true –±–ª–∏–∑–∫–æ –∫ 0
        mape = np.mean(np.abs((y_true - predictions) / (y_true + 1e-8))) * 100

        # Direction Accuracy - —Ç–æ—á–Ω–æ—Å—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è (–≤–≤–µ—Ä—Ö/–≤–Ω–∏–∑)
        direction_pred = np.sign(predictions)  # +1 –µ—Å–ª–∏ —Ä–æ—Å—Ç, -1 –µ—Å–ª–∏ –ø–∞–¥–µ–Ω–∏–µ
        direction_true = np.sign(y_true)
        direction_accuracy = np.mean(direction_pred == direction_true) * 100

        # –°—Ä–µ–¥–Ω—è—è –æ—à–∏–±–∫–∞ (–º–æ–∂–µ—Ç –±—ã—Ç—å –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–æ–π –∏–ª–∏ –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω–æ–π)
        mean_error = np.mean(predictions - y_true)

        # === 3. –í–´–í–û–î –†–ï–ó–£–õ–¨–¢–ê–¢–û–í ===
        print("=" * 60)
        print("–ú–ï–¢–†–ò–ö–ò –ö–ê–ß–ï–°–¢–í–ê –ü–†–û–ì–ù–û–ó–ê")
        print("=" * 60)
        print(f"MAE (—Å—Ä–µ–¥–Ω—è—è –∞–±—Å–æ–ª—é—Ç–Ω–∞—è –æ—à–∏–±–∫–∞):     {mae:.6f}")
        print(f"R2:                                  {r2:.6f}")
        print(f"RMSE (–∫–æ—Ä–µ–Ω—å –∏–∑ —Å—Ä–µ–¥–Ω–µ–π –∫–≤. –æ—à–∏–±–∫–∏): {rmse:.6f}")
        print(f"MAPE (–æ—à–∏–±–∫–∞ –≤ %):                   {mape:.2f}%")
        print(f"Mean Error (—Å–∏—Å—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞): {mean_error:.6f}")
        print(f"Direction Accuracy (—Ç–æ—á–Ω–æ—Å—Ç—å –∑–Ω–∞–∫–∞): {direction_accuracy:.2f}%")
        print("=" * 60)
         # assert need to be made
         
        # === 4. –î–ï–¢–ê–õ–¨–ù–ê–Ø –¢–ê–ë–õ–ò–¶–ê –ü–û –î–ù–Ø–ú ===
        comparison_df = pd.DataFrame({
            '–î–∞—Ç–∞': df_real_future.index,
            '–ü—Ä–æ–≥–Ω–æ–∑': predictions,
            '–†–µ–∞–ª—å–Ω–æ—Å—Ç—å': y_true,
            '–û—à–∏–±–∫–∞': predictions - y_true,
            '–ê–±—Å. –û—à–∏–±–∫–∞': np.abs(predictions - y_true),
            '–û—à–∏–±–∫–∞ %': np.abs((y_true - predictions) / (y_true + 1e-8)) * 100,
            '–ù–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ OK': direction_pred == direction_true
        })

        print("\n–î–ï–¢–ê–õ–¨–ù–ê–Ø –¢–ê–ë–õ–ò–¶–ê:")
        print(comparison_df.to_string(index=False))

        # === 5. –í–ò–ó–£–ê–õ–ò–ó–ê–¶–ò–Ø –û–®–ò–ë–û–ö ===
        fig, axes = plt.subplots(2, 2, figsize=(14, 10))

        # –ì—Ä–∞—Ñ–∏–∫ 1: –ü—Ä–æ–≥–Ω–æ–∑ vs –†–µ–∞–ª—å–Ω–æ—Å—Ç—å
        axes[0, 0].plot(y_true, label='–†–µ–∞–ª—å–Ω–æ—Å—Ç—å', marker='o', color='green')
        axes[0, 0].plot(predictions, label='–ü—Ä–æ–≥–Ω–æ–∑', marker='x', color='red', linestyle='--')
        axes[0, 0].set_title('–ü—Ä–æ–≥–Ω–æ–∑ vs –†–µ–∞–ª—å–Ω–æ—Å—Ç—å')
        axes[0, 0].set_xlabel('–î–µ–Ω—å')
        axes[0, 0].set_ylabel('Returns')
        axes[0, 0].legend()
        axes[0, 0].grid(True)

        # –ì—Ä–∞—Ñ–∏–∫ 2: Scatter plot (–∏–¥–µ–∞–ª—å–Ω–∞—è –ª–∏–Ω–∏—è = –¥–∏–∞–≥–æ–Ω–∞–ª—å)
        axes[0, 1].scatter(y_true, predictions, alpha=0.7)
        axes[0, 1].plot([y_true.min(), y_true.max()],
                        [y_true.min(), y_true.max()],
                        'r--', label='–ò–¥–µ–∞–ª—å–Ω—ã–π –ø—Ä–æ–≥–Ω–æ–∑')
        axes[0, 1].set_xlabel('–†–µ–∞–ª—å–Ω—ã–µ Returns')
        axes[0, 1].set_ylabel('–ü—Ä–æ–≥–Ω–æ–∑–Ω—ã–µ Returns')
        axes[0, 1].set_title('Scatter Plot: –ü—Ä–æ–≥–Ω–æ–∑ vs –†–µ–∞–ª—å–Ω–æ—Å—Ç—å')
        axes[0, 1].legend()
        axes[0, 1].grid(True)

        # –ì—Ä–∞—Ñ–∏–∫ 3: –û—à–∏–±–∫–∏ –ø–æ –¥–Ω—è–º
        axes[1, 0].bar(range(len(y_true)), predictions - y_true,
                    color=['red' if e > 0 else 'green' for e in (predictions - y_true)])
        axes[1, 0].axhline(y=0, color='black', linestyle='-', linewidth=0.5)
        axes[1, 0].set_title('–û—à–∏–±–∫–∞ –ø–æ –¥–Ω—è–º (–ü—Ä–æ–≥–Ω–æ–∑ - –†–µ–∞–ª—å–Ω–æ—Å—Ç—å)')
        axes[1, 0].set_xlabel('–î–µ–Ω—å')
        axes[1, 0].set_ylabel('–û—à–∏–±–∫–∞')
        axes[1, 0].grid(True)

        # –ì—Ä–∞—Ñ–∏–∫ 4: –ê–±—Å–æ–ª—é—Ç–Ω—ã–µ –æ—à–∏–±–∫–∏
        axes[1, 1].bar(range(len(y_true)), np.abs(predictions - y_true), color='orange')
        axes[1, 1].set_title('–ê–±—Å–æ–ª—é—Ç–Ω–∞—è –æ—à–∏–±–∫–∞ –ø–æ –¥–Ω—è–º')
        axes[1, 1].set_xlabel('–î–µ–Ω—å')
        axes[1, 1].set_ylabel('|–û—à–∏–±–∫–∞|')
        axes[1, 1].axhline(y=mae, color='red', linestyle='--', label=f'MAE = {mae:.4f}')
        axes[1, 1].legend()
        axes[1, 1].grid(True)

        plt.tight_layout()
        plt.show()

        # === 6. –°–í–û–î–ù–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê ===
        print("\n" + "=" * 60)
        print("–°–í–û–î–ù–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê:")
        print("=" * 60)
        print(f"–ü—Ä–∞–≤–∏–ª—å–Ω–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–æ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ: {np.sum(direction_pred == direction_true)} –∏–∑ {len(y_true)} –¥–Ω–µ–π")
        print(f"–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –æ—à–∏–±–∫–∞:               {np.max(np.abs(predictions - y_true)):.6f}")
        print(f"–ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –æ—à–∏–±–∫–∞:                {np.min(np.abs(predictions - y_true)):.6f}")
        print(f"–°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ –æ—à–∏–±–∫–∏:     {np.std(predictions - y_true):.6f}") 
        
        
    def save_evaluation_to_json(predictions,
                                y_true,
                                df_real_future,
                                forecaster,
                                FEATURES,
                                target,
                                mae,
                                mape,
                                rmse):
            # === 7. –°–û–•–†–ê–ù–ï–ù–ò–ï –†–ï–ó–£–õ–¨–¢–ê–¢–û–í –í JSON ===
        # 1. –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –æ—á–∏—Å—Ç–∫–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ (—á—Ç–æ–±—ã JSON –Ω–µ —Ä—É–≥–∞–ª—Å—è –Ω–∞ numpy —Ç–∏–ø—ã)
        def safe_serialize(val):
            if isinstance(val, (np.int64, np.int32)):
                return int(val)
            if isinstance(val, (np.float64, np.float32)):
                return float(val)
            if isinstance(val, (str, int, float, bool, type(None))):
                return val
            return str(val) # –î–ª—è –≤—Å–µ–≥–æ –æ—Å—Ç–∞–ª—å–Ω–æ–≥–æ (—Ñ—É–Ω–∫—Ü–∏–∏, –∫–ª–∞—Å—Å—ã) –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Å—Ç—Ä–æ–∫—É

        # 2. –°–±–æ—Ä –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ —Å –∫–∞–∂–¥–æ–π –ø–æ–¥-–º–æ–¥–µ–ª–∏ (–ø–æ —à–∞–≥–∞–º)
        # forecaster.models - —ç—Ç–æ —Å–ª–æ–≤–∞—Ä—å {step: pipeline}
        model_params_by_step = {}
        try:
            for step, model_step in forecaster.models.items():
                # –ë–µ—Ä–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ–±–µ–¥–∏–≤—à–µ–π –º–æ–¥–µ–ª–∏ –Ω–∞ —ç—Ç–æ–º —à–∞–≥–µ
                raw_params = model_step.get_params()
                # –û—á–∏—â–∞–µ–º –∏—Ö –¥–ª—è JSON
                clean_params = {k: safe_serialize(v) for k, v in raw_params.items()}
                model_params_by_step[str(step)] = clean_params
        except AttributeError:
            print("‚ö†Ô∏è –í–Ω–∏–º–∞–Ω–∏–µ: forecaster.models –Ω–µ –Ω–∞–π–¥–µ–Ω. –í–æ–∑–º–æ–∂–Ω–æ, –º–æ–¥–µ–ª—å –Ω–µ –±—ã–ª–∞ –æ–±—É—á–µ–Ω–∞.")
            model_params_by_step = "Not trained or invalid object"


        # 3. –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –∏—Ç–æ–≥–æ–≤–æ–≥–æ —Å–ª–æ–≤–∞—Ä—è
        results = {
            'date': df_real_future.index[0].strftime('%Y-%m-%d'),
            'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),

            # –ú–µ—Ç—Ä–∏–∫–∏ (–ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ—Ç—Å—è, —á—Ç–æ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ mae, rmse –∏ —Ç.–¥. —É–∂–µ —Ä–∞—Å—Å—á–∏—Ç–∞–Ω—ã —Ä–∞–Ω–µ–µ)
            'mae': float(mae),
            'rmse': float(rmse),
            'mape': float(mape),
            'mean_error': float(mean_error),
            'direction_accuracy': float(direction_accuracy),

            # –ü—Ä–æ–≥–Ω–æ–∑—ã
            'predicted': predictions.tolist(),
            'actual': y_true.tolist(),
            'errors': (predictions - y_true).tolist(),
            'directions_correct': (direction_pred == direction_true).tolist(),

            # Features –∏ Model INFO
            'features_used': FEATURES,
            'num_features': len(FEATURES),

            # ! –ò–ó–ú–ï–ù–ï–ù–ò–Ø –ó–î–ï–°–¨ !
            'model_type': type(forecaster).__name__, # –ò–º—è –≤–∞—à–µ–≥–æ –∫–ª–∞—Å—Å–∞ (AutoTunedDirectForecaster)
            'base_model_type': type(forecaster.base_pipeline.steps[-1][1]).__name__, # –ò–º—è –≤–Ω—É—Ç—Ä–µ–Ω–Ω–µ–π –º–æ–¥–µ–ª–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä HistGradientBoostingRegressor)

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ —à–∞–≥–∞–º: "1": {...}, "2": {...}
            'model_params_per_step': model_params_by_step,
            # –ú–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –æ–±—â–∏–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –≥—Ä–∏–¥–∞, –µ—Å–ª–∏ –æ–Ω–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ –∫–ª–∞—Å—Å–µ
            'grid_search_config': {
                'horizon': forecaster.horizon,
                'cv_splits': forecaster.cv_splits
            },

            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∏–Ω—Ñ–æ
            'target': target,
            'forecast_horizon': FORECAST_HORIZON,

            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
            'summary': {
                'correct_directions': int(np.sum(direction_pred == direction_true)),
                'total_days': int(len(y_true)),
                'max_error': float(np.max(np.abs(y_pred - y_true))),
                'min_error': float(np.min(np.abs(y_pred - y_true))),
                'std_error': float(np.std(y_pred - y_true))
            }
        }

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º
        filename = f"data_tests/MODEL800/result_{df_real_future.index[0].strftime('%Y%m%d')}.json"
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False)

        print(f"\n‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {filename}")
            
    @staticmethod
    def analyze_all_predictions(folder=None, results:list = None, target:str = "VM"):
        """
        –ü–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –≤—Å–µ—Ö –ø—Ä–æ–≥–Ω–æ–∑–æ–≤ –∏–∑ –ø–∞–ø–∫–∏ data_tests
        """

        # === 1. –ó–ê–ì–†–£–ó–ö–ê –í–°–ï–• –†–ï–ó–£–õ–¨–¢–ê–¢–û–í ===
        all_results = []
        json_files = glob.glob(f'{folder}/result_*.json')

        if not json_files:
            print(f"‚ùå –ù–µ—Ç —Ñ–∞–π–ª–æ–≤ –≤ –ø–∞–ø–∫–µ {folder}/")
            return None

        print(f"üìÅ –ù–∞–π–¥–µ–Ω–æ —Ñ–∞–π–ª–æ–≤: {len(json_files)}")

        for file in json_files:
            try:
                with open(file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    all_results.append(data)
            except Exception as e:
                print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ {file}: {e}")

        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –¥–∞—Ç–µ
        all_results = sorted(all_results, key=lambda x: x['date'])

        # === 2. –û–ë–©–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê ===
        total_predictions = len(all_results)
        total_days = sum(r['summary']['total_days'] for r in all_results)
        correct_directions = sum(r['summary']['correct_directions'] for r in all_results)
        overall_accuracy = (correct_directions / total_days) * 100 if total_days > 0 else 0

        avg_mae = np.mean([r['mae'] for r in all_results])
        avg_rmse = np.mean([r['rmse'] for r in all_results])
        avg_mape = np.mean([
            r['mape'] if r['mape'] <= 1000 else 0
            for r in all_results
        ])

        avg_mean_error = np.mean([r['mean_error'] for r in all_results])

        std_mae = np.std([r['mae'] for r in all_results])
        std_rmse = np.std([r['rmse'] for r in all_results])

        min_mae = min(r['mae'] for r in all_results)
        max_mae = max(r['mae'] for r in all_results)

        # === 3. –í–´–í–û–î –û–ë–©–ï–ô –°–¢–ê–¢–ò–°–¢–ò–ö–ò ===
        print("\n" + "=" * 80)
        print("–û–ë–©–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ü–û –í–°–ï–ú –ü–†–û–ì–ù–û–ó–ê–ú")
        print("=" * 80)
        print(f"üìä –ü–µ—Ä–∏–æ–¥: {all_results[0]['date']} ‚Üí {all_results[-1]['date']}")
        print(f"üìà –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ–≥–Ω–æ–∑–æ–≤: {total_predictions}")
        print(f"üìÖ –í—Å–µ–≥–æ —Å–ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–æ –¥–Ω–µ–π: {total_days}")
        print(f"\nüéØ –¢–û–ß–ù–û–°–¢–¨ –ù–ê–ü–†–ê–í–õ–ï–ù–ò–Ø:")
        print(f"   ‚îú‚îÄ –ü—Ä–∞–≤–∏–ª—å–Ω—ã—Ö: {correct_directions} –∏–∑ {total_days}")
        print(f"   ‚îî‚îÄ Overall Direction Accuracy: {overall_accuracy:.2f}%")
        print(f"\nüìâ –û–®–ò–ë–ö–ò:")
        print(f"   ‚îú‚îÄ –°—Ä–µ–¥–Ω—è—è MAE:  {avg_mae:.6f} ¬± {std_mae:.6f}")
        print(f"   ‚îú‚îÄ –°—Ä–µ–¥–Ω—è—è RMSE: {avg_rmse:.6f} ¬± {std_rmse:.6f}")
        print(f"   ‚îú‚îÄ –°—Ä–µ–¥–Ω—è—è MAPE: {avg_mape:.2f}%")
        print(f"   ‚îú‚îÄ Min MAE:      {min_mae:.6f}")
        print(f"   ‚îú‚îÄ Max MAE:      {max_mae:.6f}")
        print(f"   ‚îî‚îÄ –°–∏—Å—Ç–µ–º. –æ—à–∏–±–∫–∞: {avg_mean_error:.6f}")

        # === 4. –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ü–û –ú–û–î–ï–õ–Ø–ú ===
        unique_models = set(r.get('model_type', 'Unknown') for r in all_results)
        unique_feature_counts = set(r.get('num_features', 0) for r in all_results)

        print(f"\nüîß –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø:")
        print(f"   ‚îú‚îÄ –ú–æ–¥–µ–ª–∏: {', '.join(unique_models)}")
        print(f"   ‚îú‚îÄ –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ features: {', '.join(map(str, sorted(unique_feature_counts)))}")
        print(f"   ‚îî‚îÄ Target: {all_results[0].get(target, 'Unknown')}")
        print("=" * 80)

        # === 5. –î–ï–¢–ê–õ–¨–ù–ê–Ø –¢–ê–ë–õ–ò–¶–ê –ü–û –î–ù–Ø–ú ===
        print("\n" + "=" * 100)
        print("–î–ï–¢–ê–õ–¨–ù–ê–Ø –ò–°–¢–û–†–ò–Ø –ü–û –î–ù–Ø–ú")
        print("=" * 100)
        print(f"{'–î–∞—Ç–∞':<12} {'Dir Acc':<10} {'MAE':<12} {'RMSE':<12} {'MAPE':<10} {'Mean Err':<12} {'Features':<10}")
        print("-" * 100)

        for r in all_results:
            acc = r['direction_accuracy']
            status = '‚úÖ' if acc >= 50 else '‚ùå'
            date = r['date']
            mae_val = r['mae']
            rmse_val = r['rmse']
            mape_val = 0 if r['mape'] > 1000 else r['mape']
            mean_err = r['mean_error']
            num_feat = r.get('num_features', 'N/A')

            print(f"{date:<12} {status} {acc:>5.1f}%  {mae_val:>10.6f}  {rmse_val:>10.6f}  {mape_val:>7.2f}%  {mean_err:>10.6f}  {num_feat:>8}")

        print("=" * 100)

        # === 6. –°–û–ó–î–ê–Å–ú DATAFRAME ===
        df_results = pd.DataFrame([{
            'date': r['date'],
            'direction_accuracy': r['direction_accuracy'],
            'mae': r['mae'],
            'rmse': r['rmse'],
            'mape': r['mape'],
            'mean_error': r['mean_error'],
            'num_features': r.get('num_features', 0),
            'model_type': r.get('model_type', 'Unknown')
        } for r in all_results])

        df_results['date'] = pd.to_datetime(df_results['date'])

        # === 7. –í–ò–ó–£–ê–õ–ò–ó–ê–¶–ò–Ø ===
        fig, axes = plt.subplots(2, 2, figsize=(16, 12))

        # –ì—Ä–∞—Ñ–∏–∫ 1: Direction Accuracy –ø–æ –¥–Ω—è–º
        ax1 = axes[0, 0]
        colors = ['green' if x >= 50 else 'red' for x in df_results['direction_accuracy']]
        ax1.bar(range(len(df_results)), df_results['direction_accuracy'], color=colors, alpha=0.7)
        ax1.axhline(y=50, color='blue', linestyle='--', label='50% (Random)')
        ax1.axhline(y=overall_accuracy, color='orange', linestyle='--', label=f'Average: {overall_accuracy:.1f}%')
        ax1.set_xlabel('–ü—Ä–æ–≥–Ω–æ–∑ #')
        ax1.set_ylabel('Direction Accuracy (%)')
        ax1.set_title('Direction Accuracy –ø–æ –¥–Ω—è–º')
        ax1.legend()
        ax1.grid(True, alpha=0.3)
        
        fig, ax = plt.subplots(figsize=(16, 6))

        # Plot actual values (combines history + forecast period)
        all_dates = df_results['date'].tolist()
        all_real_values = df_results['real_values'].tolist()

        # Historical line (blue)
        ax.plot(all_dates, all_real_values, 
                linewidth=2, color='steelblue', 
                label='–ò—Å—Ç–æ—Ä–∏—è (–§–∞–∫—Ç)', zorder=1)

        # Forecast points (red with dashed line)
        forecast_dates = all_dates[-len(df_results):]  # Last N days
        forecast_predictions = df_results['predictions'].tolist()

        ax.plot(forecast_dates, forecast_predictions,
                marker='o', linestyle='--', color='red', 
                linewidth=2, markersize=6, alpha=0.8,
                label='–ü—Ä–æ–≥–Ω–æ–∑ (AI)', zorder=2)

        # Actual values during forecast (green dots)
        ax.plot(forecast_dates, all_real_values[-len(df_results):],
                marker='o', linestyle='', color='green', 
                markersize=6, alpha=0.8,
                label='–§–∞–∫—Ç –ø–æ—Å–ª–µ –ø—Ä–æ–≥–Ω–æ–∑–∞', zorder=3)

        ax.set_title(f'Walk-Forward Validation: {len(df_results)} –∏—Ç–µ—Ä–∞—Ü–∏–π', 
                    fontsize=14, fontweight='bold')
        ax.set_xlabel('–î–∞—Ç–∞')
        ax.set_ylabel('Returns (VM)')
        ax.legend(fontsize=11, loc='best')
        ax.grid(True, alpha=0.3)

        plt.tight_layout()
        plt.show()

        # –ì—Ä–∞—Ñ–∏–∫ 2: MAE –ø–æ –¥–Ω—è–º
        ax2 = axes[0, 1]
        ax2.plot(range(len(df_results)), df_results['mae'], marker='o', color='purple', label='MAE')
        ax2.axhline(y=avg_mae, color='red', linestyle='--', label=f'Average: {avg_mae:.6f}')
        ax2.fill_between(range(len(df_results)),
                        avg_mae - std_mae, avg_mae + std_mae,
                        alpha=0.2, color='red', label='¬±1 STD')
        ax2.set_xlabel('–ü—Ä–æ–≥–Ω–æ–∑ #')
        ax2.set_ylabel('MAE')
        ax2.set_title('MAE –ø–æ –¥–Ω—è–º')
        ax2.legend()
        ax2.grid(True, alpha=0.3)

        # –ì—Ä–∞—Ñ–∏–∫ 3: –°–∏—Å—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ (bias)
        ax3 = axes[1, 0]
        ax3.bar(range(len(df_results)), df_results['mean_error'],
                color=['red' if x > 0 else 'green' for x in df_results['mean_error']], alpha=0.7)
        ax3.axhline(y=0, color='black', linestyle='-', linewidth=1)
        ax3.axhline(y=avg_mean_error, color='blue', linestyle='--', label=f'Average: {avg_mean_error:.6f}')
        ax3.set_xlabel('–ü—Ä–æ–≥–Ω–æ–∑ #')
        ax3.set_ylabel('Mean Error (Bias)')
        ax3.set_title('–°–∏—Å—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ (–ü—Ä–æ–≥–Ω–æ–∑ - –†–µ–∞–ª—å–Ω–æ—Å—Ç—å)')
        ax3.legend()
        ax3.grid(True, alpha=0.3)

        # –ì—Ä–∞—Ñ–∏–∫ 4: Cumulative Direction Accuracy
        ax4 = axes[1, 1]
        cumulative_correct = np.cumsum([r['summary']['correct_directions'] for r in all_results])
        cumulative_total = np.cumsum([r['summary']['total_days'] for r in all_results])
        cumulative_accuracy = (cumulative_correct / cumulative_total) * 100
        ax4.plot(range(len(df_results)), cumulative_accuracy, marker='o', color='darkgreen', linewidth=2)
        ax4.axhline(y=50, color='blue', linestyle='--', label='50% (Random)')
        ax4.fill_between(range(len(df_results)), 50, cumulative_accuracy,
                        where=(cumulative_accuracy >= 50), alpha=0.3, color='green', label='Above random')
        ax4.fill_between(range(len(df_results)), 50, cumulative_accuracy,
                        where=(cumulative_accuracy < 50), alpha=0.3, color='red', label='Below random')
        ax4.set_xlabel('–ü—Ä–æ–≥–Ω–æ–∑ #')
        ax4.set_ylabel('Cumulative Direction Accuracy (%)')
        ax4.set_title('–ù–∞–∫–æ–ø–∏—Ç–µ–ª—å–Ω–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è')
        ax4.legend()
        ax4.grid(True, alpha=0.3)

        plt.tight_layout()
        plt.savefig(f'{folder}/analysis_summary.png', dpi=150, bbox_inches='tight')
        plt.show()

        print(f"\n‚úÖ –ì—Ä–∞—Ñ–∏–∫ —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {folder}/analysis_summary.png")

        # === 8. –°–û–•–†–ê–ù–ï–ù–ò–ï –í CSV ===
        df_results.to_csv(f'{folder}/analysis_summary.csv', index=False, encoding='utf-8')
        print(f"‚úÖ –¢–∞–±–ª–∏—Ü–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {folder}/analysis_summary.csv")

        # === 9. –°–û–•–†–ê–ù–ï–ù–ò–ï –û–¢–ß–Å–¢–ê –í MD ===
        report = f"""# –û—Ç—á—ë—Ç –ø–æ –ø—Ä–æ–≥–Ω–æ–∑–∞–º

    **–î–∞—Ç–∞ —Å–æ–∑–¥–∞–Ω–∏—è:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
    **–ü–µ—Ä–∏–æ–¥:** {all_results[0]['date']} ‚Üí {all_results[-1]['date']}

    ## –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞

    | –ú–µ—Ç—Ä–∏–∫–∞ | –ó–Ω–∞—á–µ–Ω–∏–µ |
    |---------|----------|
    | –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ–≥–Ω–æ–∑–æ–≤ | {total_predictions} |
    | –í—Å–µ–≥–æ –¥–Ω–µ–π | {total_days} |
    | –ü—Ä–∞–≤–∏–ª—å–Ω—ã—Ö –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–π | {correct_directions} / {total_days} |
    | **Overall Direction Accuracy** | **{overall_accuracy:.2f}%** |
    | –°—Ä–µ–¥–Ω—è—è MAE | {avg_mae:.6f} ¬± {std_mae:.6f} |
    | –°—Ä–µ–¥–Ω—è—è RMSE | {avg_rmse:.6f} ¬± {std_rmse:.6f} |
    | –°—Ä–µ–¥–Ω—è—è MAPE | {avg_mape:.2f}% |
    | –°–∏—Å—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ | {avg_mean_error:.6f} |

    ## –î–µ—Ç–∞–ª—å–Ω–∞—è –∏—Å—Ç–æ—Ä–∏—è

    | –î–∞—Ç–∞ | Direction Acc | MAE | RMSE | MAPE | Mean Error | Features |
    |------|---------------|-----|------|------|------------|----------|
    """

        for r in all_results:
            acc = r['direction_accuracy']
            status = '‚úÖ' if acc >= 50 else '‚ùå'
            report += f"| {r['date']} | {status} {acc:.1f}% | {r['mae']:.6f} | {r['rmse']:.6f} | {r['mape']:.2f}% | {r['mean_error']:.6f} | {r.get('num_features', 'N/A')} |\n"

        report += f"\n![Analysis Summary]({folder}/analysis_summary.png)\n"

        with open(f'{folder}/REPORT.md', 'w', encoding='utf-8') as f:
            f.write(report)

        print(f"‚úÖ –û—Ç—á—ë—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {folder}/REPORT.md")

        return df_results, all_results
    
    
    
    @staticmethod
    def analyze_all_predictions_new(folder=None, results: list = None, target: str = "VM"):
        """
        –ü–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –≤—Å–µ—Ö –ø—Ä–æ–≥–Ω–æ–∑–æ–≤
        
        Args:
            folder: Path to folder with result_*.json files (old format)
            results: List of result dictionaries (new format from walk-forward)
        """
        
        all_results = []
        
        # ‚úÖ NEW: If results provided directly, use them
        if results is not None:
            print(f"üìä Analyzing {len(results)} walk-forward results...")
            
            # Convert our format to expected format
            for r in results:
                # Extract summary stats from daily_results
                daily_results = r.get('daily_results', [])
                total_days = len(daily_results)
                correct_directions = sum(1 for d in daily_results if d.get('direction_correct', False))
                
                # Convert to expected format
                converted = {
                    'date': r.get('forecast_start', r.get('train_end_date', 'Unknown')),
                    'direction_accuracy': r.get('direction_accuracy', 0),
                    'mae': r.get('mae', 0),
                    'rmse': r.get('rmse', 0),
                    'mape': r.get('mape', 0),
                    'mean_error': r.get('mean_error', 0),
                    'num_features': r.get('num_features', 0),
                    'model_type': 'Walk-Forward',
                    'predictions': r.get('predictions', []),
                    'real_values': r.get('real_values', []),
                    
                    'summary': {
                        'total_days': total_days,
                        'correct_directions': correct_directions
                    },
                    'target': 'VM'  # You can make this configurable
                }
                all_results.append(converted)
        
        # OLD: Read from JSON files in folder
        elif folder is not None:
            json_files = glob.glob(f'{folder}/result_*.json')
            
            if not json_files:
                print(f"‚ùå –ù–µ—Ç —Ñ–∞–π–ª–æ–≤ –≤ –ø–∞–ø–∫–µ {folder}/")
                return None
            
            print(f"üìÅ –ù–∞–π–¥–µ–Ω–æ —Ñ–∞–π–ª–æ–≤: {len(json_files)}")
            
            for file in json_files:
                try:
                    with open(file, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                        all_results.append(data)
                except Exception as e:
                    print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ {file}: {e}")
        
        else:
            print("‚ùå –ù–µ–æ–±—Ö–æ–¥–∏–º–æ —É–∫–∞–∑–∞—Ç—å –ª–∏–±–æ folder, –ª–∏–±–æ results")
            return None
        
        if not all_results:
            print("‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
            return None
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –¥–∞—Ç–µ
        all_results = sorted(all_results, key=lambda x: x['date'])
        
        # === 2. –û–ë–©–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê ===
        total_predictions = len(all_results)
        total_days = sum(r['summary']['total_days'] for r in all_results)
        correct_directions = sum(r['summary']['correct_directions'] for r in all_results)
        overall_accuracy = (correct_directions / total_days) * 100 if total_days > 0 else 0
        
        avg_mae = np.mean([r['mae'] for r in all_results])
        avg_rmse = np.mean([r['rmse'] for r in all_results])
        avg_mape = np.mean([
            r['mape'] if r['mape'] <= 1000 else 0
            for r in all_results
        ])
        
        avg_mean_error = np.mean([r['mean_error'] for r in all_results])
        
        std_mae = np.std([r['mae'] for r in all_results])
        std_rmse = np.std([r['rmse'] for r in all_results])
        
        min_mae = min(r['mae'] for r in all_results)
        max_mae = max(r['mae'] for r in all_results)
        
        # === 3. –í–´–í–û–î –û–ë–©–ï–ô –°–¢–ê–¢–ò–°–¢–ò–ö–ò ===
        print("\n" + "=" * 80)
        print("–û–ë–©–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ü–û –í–°–ï–ú –ü–†–û–ì–ù–û–ó–ê–ú")
        print("=" * 80)
        print(f"üìä –ü–µ—Ä–∏–æ–¥: {all_results[0]['date']} ‚Üí {all_results[-1]['date']}")
        print(f"üìà –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ–≥–Ω–æ–∑–æ–≤: {total_predictions}")
        print(f"üìÖ –í—Å–µ–≥–æ —Å–ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–æ –¥–Ω–µ–π: {total_days}")
        print(f"\nüéØ –¢–û–ß–ù–û–°–¢–¨ –ù–ê–ü–†–ê–í–õ–ï–ù–ò–Ø:")
        print(f"   ‚îú‚îÄ –ü—Ä–∞–≤–∏–ª—å–Ω—ã—Ö: {correct_directions} –∏–∑ {total_days}")
        print(f"   ‚îî‚îÄ Overall Direction Accuracy: {overall_accuracy:.2f}%")
        print(f"\nüìâ –û–®–ò–ë–ö–ò:")
        print(f"   ‚îú‚îÄ –°—Ä–µ–¥–Ω—è—è MAE:  {avg_mae:.6f} ¬± {std_mae:.6f}")
        print(f"   ‚îú‚îÄ –°—Ä–µ–¥–Ω—è—è RMSE: {avg_rmse:.6f} ¬± {std_rmse:.6f}")
        print(f"   ‚îú‚îÄ –°—Ä–µ–¥–Ω—è—è MAPE: {avg_mape:.2f}%")
        print(f"   ‚îú‚îÄ Min MAE:      {min_mae:.6f}")
        print(f"   ‚îú‚îÄ Max MAE:      {max_mae:.6f}")
        print(f"   ‚îî‚îÄ –°–∏—Å—Ç–µ–º. –æ—à–∏–±–∫–∞: {avg_mean_error:.6f}")
        
        # === 4. –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ü–û –ú–û–î–ï–õ–Ø–ú ===
        unique_models = set(r.get('model_type', 'Unknown') for r in all_results)
        unique_feature_counts = set(r.get('num_features', 0) for r in all_results)
        
        print(f"\nüîß –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø:")
        print(f"   ‚îú‚îÄ –ú–æ–¥–µ–ª–∏: {', '.join(unique_models)}")
        print(f"   ‚îú‚îÄ –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ features: {', '.join(map(str, sorted(unique_feature_counts)))}")
        print(f"   ‚îî‚îÄ Target: {all_results[0].get('target', 'Unknown')}")
        print("=" * 80)
        
        # === 5. –î–ï–¢–ê–õ–¨–ù–ê–Ø –¢–ê–ë–õ–ò–¶–ê –ü–û –î–ù–Ø–ú ===
        print("\n" + "=" * 100)
        print("–î–ï–¢–ê–õ–¨–ù–ê–Ø –ò–°–¢–û–†–ò–Ø –ü–û –î–ù–Ø–ú")
        print("=" * 100)
        print(f"{'–î–∞—Ç–∞':<12} {'Dir Acc':<10} {'MAE':<12} {'RMSE':<12} {'MAPE':<10} {'Mean Err':<12} {'Features':<10}")
        print("-" * 100)
        
        for r in all_results:
            acc = r['direction_accuracy']
            status = '‚úÖ' if acc >= 50 else '‚ùå'
            date = r['date']
            mae_val = r['mae']
            rmse_val = r['rmse']
            mape_val = 0 if r['mape'] > 1000 else r['mape']
            mean_err = r['mean_error']
            num_feat = r.get('num_features', 'N/A')
            
            print(f"{date:<12} {status} {acc:>5.1f}%  {mae_val:>10.6f}  {rmse_val:>10.6f}  {mape_val:>7.2f}%  {mean_err:>10.6f}  {num_feat:>8}")
        
        print("=" * 100)
        
        # === 6. –°–û–ó–î–ê–Å–ú DATAFRAME ===
   
        df_results = pd.DataFrame([{
            'date': r['date'],
            'direction_accuracy': r['direction_accuracy'],
            'mae': r['mae'],
            'rmse': r['rmse'],
            'mape': r['mape'],
            'mean_error': r['mean_error'],
            'num_features': r.get('num_features', 0),
            'model_type': r.get('model_type', 'Unknown'),
            # ‚úÖ ADD THESE TWO LINES:
            'predictions': r['predictions'][0] if isinstance(r['predictions'], list) else r['predictions'],
            'real_values': r['real_values'][0] if isinstance(r['real_values'], list) else r['real_values']
        } for r in all_results])

        df_results['date'] = pd.to_datetime(df_results['date'])
        
        
        # Your plotting code
        dates = pd.to_datetime(df_results['date'])
        
        # Prepare data series
        real_series = df_results['real_values']
        pred_series = df_results['predictions']

        plt.figure(figsize=(16, 6))

        # 1. Plot Reality (Solid Line) - Acts as your "History"
        plt.plot(dates, real_series, 
                 label="–†–µ–∞–ª—å–Ω–æ—Å—Ç—å (Fact)", 
                 color='steelblue', 
                 linewidth=2, 
                 linestyle='-')

        # 2. Plot Predictions (Dashed Line) - Acts as your "Forecast"
        plt.plot(dates, pred_series, 
                 label="–ü—Ä–æ–≥–Ω–æ–∑ AI", 
                 color='tab:red', 
                 linewidth=2, 
                 linestyle='--', 
                 alpha=0.9)

        # 3. Highlight differences (Optional but looks like the screenshot)
        # Fill area between lines to show error magnitude
        plt.fill_between(dates, real_series, pred_series, 
                         color='gray', alpha=0.1, label='Error Gap')

        plt.title(f"Walk-Forward Validation: {len(df_results)} Days", fontsize=14)
        plt.xlabel("–î–∞—Ç–∞")
        plt.ylabel("Target Value")
        plt.legend(loc="upper left")
        plt.grid(True, alpha=0.3)
        
        # Format X-Axis to look nice
        import matplotlib.dates as mdates
        plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))
        plt.gca().xaxis.set_major_locator(mdates.AutoDateLocator())
        plt.gcf().autofmt_xdate() # Rotate dates slightly

        plt.tight_layout()

        # Save
        save_path = folder if folder else './results'
        os.makedirs(save_path, exist_ok=True)
        plt.savefig(f'{save_path}/predictions_vs_reality.png', dpi=150, bbox_inches='tight')
        print(f"‚úÖ Plot saved: {save_path}/predictions_vs_reality.png")

        plt.show()
        
        # === 7. –í–ò–ó–£–ê–õ–ò–ó–ê–¶–ò–Ø ===
        fig, axes = plt.subplots(2, 2, figsize=(16, 12))
        
        # –ì—Ä–∞—Ñ–∏–∫ 1: Direction Accuracy –ø–æ –¥–Ω—è–º
        ax1 = axes[0, 0]
        colors = ['green' if x >= 50 else 'red' for x in df_results['direction_accuracy']]
        ax1.bar(range(len(df_results)), df_results['direction_accuracy'], color=colors, alpha=0.7)
        ax1.axhline(y=50, color='blue', linestyle='--', label='50% (Random)')
        ax1.axhline(y=overall_accuracy, color='orange', linestyle='--', label=f'Average: {overall_accuracy:.1f}%')
        ax1.set_xlabel('–ü—Ä–æ–≥–Ω–æ–∑ #')
        ax1.set_ylabel('Direction Accuracy (%)')
        ax1.set_title('Direction Accuracy –ø–æ –¥–Ω—è–º')
        ax1.legend()
        ax1.grid(True, alpha=0.3)
        
        # –ì—Ä–∞—Ñ–∏–∫ 2: MAE –ø–æ –¥–Ω—è–º
        ax2 = axes[0, 1]
        ax2.plot(range(len(df_results)), df_results['mae'], marker='o', color='purple', label='MAE')
        ax2.axhline(y=avg_mae, color='red', linestyle='--', label=f'Average: {avg_mae:.6f}')
        ax2.fill_between(range(len(df_results)),
                        avg_mae - std_mae, avg_mae + std_mae,
                        alpha=0.2, color='red', label='¬±1 STD')
        ax2.set_xlabel('–ü—Ä–æ–≥–Ω–æ–∑ #')
        ax2.set_ylabel('MAE')
        ax2.set_title('MAE –ø–æ –¥–Ω—è–º')
        ax2.legend()
        ax2.grid(True, alpha=0.3)
        
        # –ì—Ä–∞—Ñ–∏–∫ 3: –°–∏—Å—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ (bias)
        ax3 = axes[1, 0]
        ax3.bar(range(len(df_results)), df_results['mean_error'],
                color=['red' if x > 0 else 'green' for x in df_results['mean_error']], alpha=0.7)
        ax3.axhline(y=0, color='black', linestyle='-', linewidth=1)
        ax3.axhline(y=avg_mean_error, color='blue', linestyle='--', label=f'Average: {avg_mean_error:.6f}')
        ax3.set_xlabel('–ü—Ä–æ–≥–Ω–æ–∑ #')
        ax3.set_ylabel('Mean Error (Bias)')
        ax3.set_title('–°–∏—Å—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ (–ü—Ä–æ–≥–Ω–æ–∑ - –†–µ–∞–ª—å–Ω–æ—Å—Ç—å)')
        ax3.legend()
        ax3.grid(True, alpha=0.3)
        
        # –ì—Ä–∞—Ñ–∏–∫ 4: Cumulative Direction Accuracy
        ax4 = axes[1, 1]
        cumulative_correct = np.cumsum([r['summary']['correct_directions'] for r in all_results])
        cumulative_total = np.cumsum([r['summary']['total_days'] for r in all_results])
        cumulative_accuracy = (cumulative_correct / cumulative_total) * 100
        ax4.plot(range(len(df_results)), cumulative_accuracy, marker='o', color='darkgreen', linewidth=2)
        ax4.axhline(y=50, color='blue', linestyle='--', label='50% (Random)')
        ax4.fill_between(range(len(df_results)), 50, cumulative_accuracy,
                        where=(cumulative_accuracy >= 50), alpha=0.3, color='green', label='Above random')
        ax4.fill_between(range(len(df_results)), 50, cumulative_accuracy,
                        where=(cumulative_accuracy < 50), alpha=0.3, color='red', label='Below random')
        ax4.set_xlabel('–ü—Ä–æ–≥–Ω–æ–∑ #')
        ax4.set_ylabel('Cumulative Direction Accuracy (%)')
        ax4.set_title('–ù–∞–∫–æ–ø–∏—Ç–µ–ª—å–Ω–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è')
        ax4.legend()
        ax4.grid(True, alpha=0.3)
        
        plt.plot()
        
        plt.tight_layout()
        
        # ‚úÖ Save plot
        if folder:
            plt.savefig(f'{folder}/analysis_summary.png', dpi=150, bbox_inches='tight')
            print(f"\n‚úÖ –ì—Ä–∞—Ñ–∏–∫ —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {folder}/analysis_summary.png")
        else:
            plt.savefig('./analysis_summary.png', dpi=150, bbox_inches='tight')
            print(f"\n‚úÖ –ì—Ä–∞—Ñ–∏–∫ —Å–æ—Ö—Ä–∞–Ω—ë–Ω: ./analysis_summary.png")
        
        plt.show()
        
        # === 8. –°–û–•–†–ê–ù–ï–ù–ò–ï –í CSV ===
        csv_path = f'{folder}/analysis_summary.csv' if folder else './analysis_summary.csv'
        df_results.to_csv(csv_path, index=False, encoding='utf-8')
        print(f"‚úÖ –¢–∞–±–ª–∏—Ü–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {csv_path}")
        
        # === 9. –°–û–•–†–ê–ù–ï–ù–ò–ï –û–¢–ß–Å–¢–ê –í MD ===
        report = f"""# –û—Ç—á—ë—Ç –ø–æ –ø—Ä–æ–≥–Ω–æ–∑–∞–º

    **–î–∞—Ç–∞ —Å–æ–∑–¥–∞–Ω–∏—è:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
    **–ü–µ—Ä–∏–æ–¥:** {all_results[0]['date']} ‚Üí {all_results[-1]['date']}

    ## –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞

    | –ú–µ—Ç—Ä–∏–∫–∞ | –ó–Ω–∞—á–µ–Ω–∏–µ |
    |---------|----------|
    | –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ–≥–Ω–æ–∑–æ–≤ | {total_predictions} |
    | –í—Å–µ–≥–æ –¥–Ω–µ–π | {total_days} |
    | –ü—Ä–∞–≤–∏–ª—å–Ω—ã—Ö –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–π | {correct_directions} / {total_days} |
    | **Overall Direction Accuracy** | **{overall_accuracy:.2f}%** |
    | –°—Ä–µ–¥–Ω—è—è MAE | {avg_mae:.6f} ¬± {std_mae:.6f} |
    | –°—Ä–µ–¥–Ω—è—è RMSE | {avg_rmse:.6f} ¬± {std_rmse:.6f} |
    | –°—Ä–µ–¥–Ω—è—è MAPE | {avg_mape:.2f}% |
    | –°–∏—Å—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ | {avg_mean_error:.6f} |

    ## –î–µ—Ç–∞–ª—å–Ω–∞—è –∏—Å—Ç–æ—Ä–∏—è

  
    | –î–∞—Ç–∞ | Direction Acc | Prediction | Reality | MAE | RMSE | MAPE | Mean Error | Features |
    |------|---------------|------------|---------|-----|------|------|------------|----------|
    """

        for r in all_results:
            acc = r['direction_accuracy']
            status = '‚úÖ' if acc >= 50 else '‚ùå'
            
            # Extract prediction and reality
            pred = r['predictions'][0] if isinstance(r['predictions'], list) else r['predictions']
            real = r['real_values'][0] if isinstance(r['real_values'], list) else r['real_values']
            
            report += f"| {r['date']} | {status} {acc:.1f}% | {pred:.4f} | {real:.4f} | {r['mae']:.6f} | {r['rmse']:.6f} | {r['mape']:.2f}% | {r['mean_error']:.6f} | {r.get('num_features', 'N/A')} |\n"

        # ‚úÖ Add visualizations (handle None folder)
        report += f"\n## Visualizations\n\n"

        if folder:
            report += f"![Analysis Summary]({folder}/analysis_summary.png)\n\n"
            report += f"![Predictions vs Reality]({folder}/predictions_vs_reality.png)\n"
        else:
            report += f"![Analysis Summary](./analysis_summary.png)\n\n"
            report += f"![Predictions vs Reality](./predictions_vs_reality.png)\n"

        # ‚úÖ Set report path (handle None folder)
        report_path = f'{folder}/REPORT.md' if folder else './REPORT.md'

        # ‚úÖ Create directory if needed
        if folder:
            os.makedirs(folder, exist_ok=True)

        # ‚úÖ Write report
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(report)

        print(f"‚úÖ –û—Ç—á—ë—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {report_path}")

        return df_results, all_results

            


class CustomForecaster:
    def __init__(self, base_pipeline, param_grid=None, horizon=7, cv_splits=3,one_time_grid_search=True):
        """
        base_pipeline: –ø–∞–π–ø–ª–∞–π–Ω (Scaler + Model)
        param_grid: —Å–µ—Ç–∫–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –¥–ª—è GridSearch
        horizon: –≥–æ—Ä–∏–∑–æ–Ω—Ç –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è
        cv_splits: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–æ–ª–¥–æ–≤ –¥–ª—è TimeSeriesSplit
        """
        self.base_pipeline = base_pipeline
        self.param_grid = param_grid
        self.horizon = horizon
        self.cv_splits = cv_splits
        self.one_time_grid_search = one_time_grid_search    

        # –°–ª–æ–≤–∞—Ä—å –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –ª—É—á—à–∏—Ö –º–æ–¥–µ–ª–µ–π –ø–æ —à–∞–≥–∞–º: {1: model_step_1, 2: model_step_2...}
        self.models = {}
        # –°–ª–æ–≤–∞—Ä—å –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –∏—Å—Ç–æ—Ä–∏–∏ –ª—É—á—à–∏—Ö —Å–∫–æ—Ä–æ–≤ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        self.results = {}

    def train(self, X, y):
        print(f"–ù–∞—á–∏–Ω–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ {self.horizon} –º–æ–¥–µ–ª–µ–π —Å –ø–æ–¥–±–æ—Ä–æ–º –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤...")

        for step in range(1, self.horizon + 1):
            # 1. –§–æ—Ä–º–∏—Ä—É–µ–º —Ç–∞—Ä–≥–µ—Ç –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —à–∞–≥–∞ (—Å–¥–≤–∏–≥ –Ω–∞–∑–∞–¥)
            y_shifted = y.shift(-step)

            # 2. –£–±–∏—Ä–∞–µ–º NaN –≤ –∫–æ–Ω—Ü–µ (–¥–∞–Ω–Ω—ã–µ, –¥–ª—è –∫–æ—Ç–æ—Ä—ã—Ö –±—É–¥—É—â–µ–µ –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ)
            valid_indices = y_shifted.dropna().index
            X_subset = X.loc[valid_indices]
            y_subset = y_shifted.loc[valid_indices]

            # 3. –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—é –¥–ª—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤
            # –≠—Ç–æ –≤–∞–∂–Ω–æ! TimeSeriesSplit –≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ—Ç, —á—Ç–æ train –≤—Å–µ–≥–¥–∞ –≤ –ø—Ä–æ—à–ª–æ–º, –∞ test –≤ –±—É–¥—É—â–µ–º
            tscv = TimeSeriesSplit(n_splits=self.cv_splits)

            # 4. –°–æ–∑–¥–∞–µ–º GridSearchCV
            # –í–∞–∂–Ω–æ: clone —Å–æ–∑–¥–∞–µ—Ç —á–∏—Å—Ç—É—é –∫–æ–ø–∏—é –ø–∞–π–ø–ª–∞–π–Ω–∞
            if self.param_grid is not None:
            
                grid = GridSearchCV(
                    estimator=clone(self.base_pipeline),
                    param_grid=self.param_grid,
                    scoring="neg_mean_absolute_percentage_error", # –í–∞—à–∞ –º–µ—Ç—Ä–∏–∫–∞
                    cv=tscv,
                    n_jobs=-1,
                    verbose=1 # –ú–æ–∂–Ω–æ –ø–æ—Å—Ç–∞–≤–∏—Ç—å 1, —á—Ç–æ–±—ã –≤–∏–¥–µ—Ç—å –ø—Ä–æ–≥—Ä–µ—Å—Å –≤–Ω—É—Ç—Ä–∏ —à–∞–≥–∞
                )
                # 5. –ó–∞–ø—É—Å–∫–∞–µ–º –ø–æ–∏—Å–∫ –ª—É—á—à–∏—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –¥–ª—è –¢–ï–ö–£–©–ï–ì–û —à–∞–≥–∞ (step)
                grid.fit(X_subset, y_subset)

                # 6. –°–æ—Ö—Ä–∞–Ω—è–µ–º –ª—É—á—à—É—é –º–æ–¥–µ–ª—å (–æ–Ω–∞ —É–∂–µ –æ–±—É—á–µ–Ω–∞ –Ω–∞ –≤—Å–µ–º X_subset –≤–Ω—É—Ç—Ä–∏ grid.fit)
                self.models[step] = grid.best_estimator_
                self.results[step] = grid.best_score_

                print(f"–®–∞–≥ {step}/{self.horizon} –≥–æ—Ç–æ–≤. –õ—É—á—à–∏–π Score (MAPE): {grid.best_score_:.4f}")
                # –ú–æ–∂–Ω–æ –≤—ã–≤–µ—Å—Ç–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã, –µ—Å–ª–∏ –∏–Ω—Ç–µ—Ä–µ—Å–Ω–æ:
                # print(f"Best params step {step}: {grid.best_params_}")
                print("Train ist fertig mit GridSearchCV.")
                
                
            elif self.param_grid is not None and self.one_time_grid_search:
                pass
            
            else:
                
                model = clone(self.base_pipeline)
                model.fit(X_subset, y_subset)

                self.models[step] = model
                self.results[step] = None
                
                print(f"–®–∞–≥ {step}/{self.horizon} –≥–æ—Ç–æ–≤ (–±–µ–∑ GridSearch).")
                   
    def predict_future(self, X_current):
        """
        –ü—Ä–æ–≥–Ω–æ–∑ –æ—Ç –ø–æ—Å–ª–µ–¥–Ω–µ–π —Ç–æ—á–∫–∏ –¥–∞–Ω–Ω—ã—Ö (X_current - —ç—Ç–æ 1 —Å—Ç—Ä–æ–∫–∞ DataFrame/Series)
        """
        forecasts = []
        days = []

        # X_current –º–æ–∂–µ—Ç –ø—Ä–∏–π—Ç–∏ –∫–∞–∫ Series, –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ DataFrame (—Ç—Ä–∞–Ω—Å–ø–æ–Ω–∏—Ä—É–µ–º)
        if isinstance(X_current, pd.Series):
            X_current = X_current.to_frame().T

        for step in range(1, self.horizon + 1):
            model = self.models[step]
            # –î–µ–ª–∞–µ–º –ø—Ä–µ–¥–∏–∫—Ç
            pred = model.predict(X_current)[0]
            ### How to realize it 
                          
            forecasts.append(pred)
            days.append(step)

        return pd.DataFrame({'step': days, 'prediction': forecasts})
    

class OptunaForecaster:
    def __init__(self, base_pipeline, param_grid=None, horizon=7, cv_splits=3,one_time_grid_search=True):
        """
        base_pipeline: –ø–∞–π–ø–ª–∞–π–Ω (Scaler + Model)
        param_grid: —Å–µ—Ç–∫–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –¥–ª—è GridSearch
        horizon: –≥–æ—Ä–∏–∑–æ–Ω—Ç –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è
        cv_splits: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–æ–ª–¥–æ–≤ –¥–ª—è TimeSeriesSplit
        """
        self.base_pipeline = base_pipeline
        self.param_grid = param_grid
        self.horizon = horizon
        self.cv_splits = cv_splits
        self.one_time_grid_search = one_time_grid_search    

        # –°–ª–æ–≤–∞—Ä—å –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –ª—É—á—à–∏—Ö –º–æ–¥–µ–ª–µ–π –ø–æ —à–∞–≥–∞–º: {1: model_step_1, 2: model_step_2...}
        self.models = {}
        # –°–ª–æ–≤–∞—Ä—å –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –∏—Å—Ç–æ—Ä–∏–∏ –ª—É—á—à–∏—Ö —Å–∫–æ—Ä–æ–≤ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        self.results = {}

    def train(self, X, y):
        print(f"–ù–∞—á–∏–Ω–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ {self.horizon} –º–æ–¥–µ–ª–µ–π —Å –ø–æ–¥–±–æ—Ä–æ–º –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤...")

        for step in range(1, self.horizon + 1):
            # 1. –§–æ—Ä–º–∏—Ä—É–µ–º —Ç–∞—Ä–≥–µ—Ç –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —à–∞–≥–∞ (—Å–¥–≤–∏–≥ –Ω–∞–∑–∞–¥)
            y_shifted = y.shift(-step)

            # 2. –£–±–∏—Ä–∞–µ–º NaN –≤ –∫–æ–Ω—Ü–µ (–¥–∞–Ω–Ω—ã–µ, –¥–ª—è –∫–æ—Ç–æ—Ä—ã—Ö –±—É–¥—É—â–µ–µ –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ)
            valid_indices = y_shifted.dropna().index
            X_subset = X.loc[valid_indices]
            y_subset = y_shifted.loc[valid_indices]

            # 3. –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—é –¥–ª—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤
            # –≠—Ç–æ –≤–∞–∂–Ω–æ! TimeSeriesSplit –≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ—Ç, —á—Ç–æ train –≤—Å–µ–≥–¥–∞ –≤ –ø—Ä–æ—à–ª–æ–º, –∞ test –≤ –±—É–¥—É—â–µ–º
            tscv = TimeSeriesSplit(n_splits=self.cv_splits)

            # 4. –°–æ–∑–¥–∞–µ–º GridSearchCV
            # –í–∞–∂–Ω–æ: clone —Å–æ–∑–¥–∞–µ—Ç —á–∏—Å—Ç—É—é –∫–æ–ø–∏—é –ø–∞–π–ø–ª–∞–π–Ω–∞
            if self.param_grid is not None:
            
                grid = GridSearchCV(
                    estimator=clone(self.base_pipeline),
                    param_grid=self.param_grid,
                    scoring="neg_mean_absolute_percentage_error", # –í–∞—à–∞ –º–µ—Ç—Ä–∏–∫–∞
                    cv=tscv,
                    n_jobs=-1,
                    verbose=1 # –ú–æ–∂–Ω–æ –ø–æ—Å—Ç–∞–≤–∏—Ç—å 1, —á—Ç–æ–±—ã –≤–∏–¥–µ—Ç—å –ø—Ä–æ–≥—Ä–µ—Å—Å –≤–Ω—É—Ç—Ä–∏ —à–∞–≥–∞
                )
                # 5. –ó–∞–ø—É—Å–∫–∞–µ–º –ø–æ–∏—Å–∫ –ª—É—á—à–∏—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –¥–ª—è –¢–ï–ö–£–©–ï–ì–û —à–∞–≥–∞ (step)
                grid.fit(X_subset, y_subset)

                # 6. –°–æ—Ö—Ä–∞–Ω—è–µ–º –ª—É—á—à—É—é –º–æ–¥–µ–ª—å (–æ–Ω–∞ —É–∂–µ –æ–±—É—á–µ–Ω–∞ –Ω–∞ –≤—Å–µ–º X_subset –≤–Ω—É—Ç—Ä–∏ grid.fit)
                self.models[step] = grid.best_estimator_
                self.results[step] = grid.best_score_

                print(f"–®–∞–≥ {step}/{self.horizon} –≥–æ—Ç–æ–≤. –õ—É—á—à–∏–π Score (MAPE): {grid.best_score_:.4f}")
                # –ú–æ–∂–Ω–æ –≤—ã–≤–µ—Å—Ç–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã, –µ—Å–ª–∏ –∏–Ω—Ç–µ—Ä–µ—Å–Ω–æ:
                # print(f"Best params step {step}: {grid.best_params_}")
                print("Train ist fertig mit GridSearchCV.")
                
                
            elif self.param_grid is not None and self.one_time_grid_search:
                pass
            
            else:
                
                model = clone(self.base_pipeline)
                model.fit(X_subset, y_subset)

                self.models[step] = model
                self.results[step] = None
                
                print(f"–®–∞–≥ {step}/{self.horizon} –≥–æ—Ç–æ–≤ (–±–µ–∑ GridSearch).")
                   
    def predict_future(self, X_current):
        """
        –ü—Ä–æ–≥–Ω–æ–∑ –æ—Ç –ø–æ—Å–ª–µ–¥–Ω–µ–π —Ç–æ—á–∫–∏ –¥–∞–Ω–Ω—ã—Ö (X_current - —ç—Ç–æ 1 —Å—Ç—Ä–æ–∫–∞ DataFrame/Series)
        """
        forecasts = []
        days = []

        # X_current –º–æ–∂–µ—Ç –ø—Ä–∏–π—Ç–∏ –∫–∞–∫ Series, –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ DataFrame (—Ç—Ä–∞–Ω—Å–ø–æ–Ω–∏—Ä—É–µ–º)
        if isinstance(X_current, pd.Series):
            X_current = X_current.to_frame().T

        for step in range(1, self.horizon + 1):
            model = self.models[step]
            # –î–µ–ª–∞–µ–º –ø—Ä–µ–¥–∏–∫—Ç
            pred = model.predict(X_current)[0]
            ### How to realize it 
                          
            forecasts.append(pred)
            days.append(step)

        return pd.DataFrame({'step': days, 'prediction': forecasts})
    
    


class BaselineForecaster:
    def __init__(self, horizon=7):
        self.models = {} # –°–ª–æ–≤–∞—Ä—å –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è 7 –æ–±—É—á–µ–Ω–Ω—ã—Ö –ø–∞–π–ø–ª–∞–π–Ω–æ–≤
        self.horizon = horizon   # –ü—Ä–æ–≥–Ω–æ–∑ –Ω–∞ 7 –¥–Ω–µ–π –≤–ø–µ—Ä–µ–¥

    def train(self, X_train, y_train):
        """
        –û–±—É—á–∞–µ—Ç 7 –æ—Ç–¥–µ–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π.
        X_train: –ø—Ä–∏–∑–Ω–∞–∫–∏ (pandas DataFrame)
        y_train: —Ü–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è (pandas Series) –Ω–∞ —Ç–µ–∫—É—â–∏–π –¥–µ–Ω—å
        """
        print("–ù–∞—á–∏–Ω–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ 7 –º–æ–¥–µ–ª–µ–π...")

        for step in range(1, self.horizon + 1):
            # 1. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –¥–Ω—è (step)
            # –ï—Å–ª–∏ step=1, –º—ã —É—á–∏–º—Å—è –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞—Ç—å t+1.
            # –ï—Å–ª–∏ step=7, –º—ã —É—á–∏–º—Å—è –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞—Ç—å t+7.

            # –°–¥–≤–∏–≥–∞–µ–º —Ç–∞—Ä–≥–µ—Ç –Ω–∞–∑–∞–¥, —á—Ç–æ–±—ã –Ω–∞–ø—Ä–æ—Ç–∏–≤ X(t) —Å—Ç–æ—è–ª y(t+step)
            y_shifted = y_train.shift(-step)

            # 2. –í—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
            # –ù–∞–º –Ω—É–∂–Ω–æ —É–¥–∞–ª–∏—Ç—å –ø–æ—Å–ª–µ–¥–Ω–∏–µ 'step' —Å—Ç—Ä–æ–∫, —Ç–∞–∫ –∫–∞–∫ —É –Ω–∏—Ö –Ω–µ—Ç –±—É–¥—É—â–µ–≥–æ —Ç–∞—Ä–≥–µ—Ç–∞ (NaN)
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∏–Ω–¥–µ–∫—Å—ã –∏–∑ y_shifted, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ NaN
            valid_indices = y_shifted.dropna().index

            X_subset = X_train.loc[valid_indices]
            y_subset = y_shifted.loc[valid_indices]

            # 3. –°–æ–∑–¥–∞–Ω–∏–µ –ø–∞–π–ø–ª–∞–π–Ω–∞: –°–∫–∞–ª–µ—Ä -> –†–µ–≥—Ä–µ—Å—Å–∏—è
            # Pipeline —Å–∞–º –æ–±—É—á–∏—Ç scaler –Ω–∞ X_subset –∏ –ø—Ä–∏–º–µ–Ω–∏—Ç –µ–≥–æ
            pipe = Pipeline([
                ('scaler', StandardScaler()),
                ('regressor', LinearRegression())
            ])

            # 4. –û–±—É—á–µ–Ω–∏–µ
            pipe.fit(X_subset, y_subset)

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å
            self.models[step] = pipe
            print(f"–ú–æ–¥–µ–ª—å –¥–ª—è –¥–Ω—è +{step} –æ–±—É—á–µ–Ω–∞.")

    def predict(self, X_input):
        """
        –î–µ–ª–∞–µ—Ç –ø—Ä–æ–≥–Ω–æ–∑ –Ω–∞ 7 –¥–Ω–µ–π –≤–ø–µ—Ä–µ–¥ –Ω–∞ –æ—Å–Ω–æ–≤–µ –í–•–û–î–ù–´–• –¥–∞–Ω–Ω—ã—Ö.
        X_input: –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ –¥–Ω—è (–æ–¥–Ω–∞ —Å—Ç—Ä–æ–∫–∞ –∏–ª–∏ DataFrame).
        """
        forecasts = {}

        # –ü—Ä–æ—Ö–æ–¥–∏–º –ø–æ –≤—Å–µ–º 7 –º–æ–¥–µ–ª—è–º
        for step in range(1, self.horizon + 1):
            model = self.models[step]

            # –ú–æ–¥–µ–ª—å —Å–∞–º–∞ –æ—Ç—Å–∫–∞–ª–∏—Ä—É–µ—Ç –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ (–≤–Ω—É—Ç—Ä–∏ pipe) –∏ —Å–¥–µ–ª–∞–µ—Ç –ø—Ä–æ–≥–Ω–æ–∑
            pred = model.predict(X_input)

            # –ï—Å–ª–∏ –ø–æ–¥–∞–ª–∏ –æ–¥–Ω—É —Å—Ç—Ä–æ–∫—É, –±–µ—Ä–µ–º –∑–Ω–∞—á–µ–Ω–∏–µ, –µ—Å–ª–∏ –º–Ω–æ–≥–æ - –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –º–∞—Å—Å–∏–≤
            if len(pred) == 1:
                forecasts[f'Day_{step}'] = pred[0]
            else:
                forecasts[f'Day_{step}'] = pred

        return forecasts
    
    
    

    